{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Breast Cancer Classification\n",
        "\n",
        "---\n",
        "\n",
        "Last Updated: 20/12/2022"
      ],
      "metadata": {
        "id": "SYHx1MqQzBZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieving dataset\n",
        "\n",
        "The dataset used is Breast Histopathology Images data from Kaggle (https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images). It contains 277,524 patches of size 50 x 50 extracted from 162 whole mount slide images of Breast Cancer (BCa) specimens scanned at 40x. There are 198,738 IDC negative and 78,786 IDC positive patches."
      ],
      "metadata": {
        "id": "HWKK9JcRA4Nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload kaggle API token\n",
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "uploaded = files.upload() # upload the kaggle json API token"
      ],
      "metadata": {
        "id": "xbPAO_oL11nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the dataset from kaggle\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d paultimothymooney/breast-histopathology-images"
      ],
      "metadata": {
        "id": "MYinXlrKA_wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the folder\n",
        "!unzip breast-histopathology-images.zip -d original"
      ],
      "metadata": {
        "id": "vKeVzNw5BEoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "R_T1KIHiBOMj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3MoBsgizAcq"
      },
      "outputs": [],
      "source": [
        "# Project structure organization\n",
        "import os\n",
        "import random \n",
        "import shutil \n",
        "\n",
        "# Preprocessing\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from tensorflow.keras.utils import to_categorical \n",
        "\n",
        "# Training\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense # model layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping # callbacks\n",
        "from tensorflow.keras.optimizers import Adagrad # optimizer\n",
        "\n",
        "# Results\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Configuration"
      ],
      "metadata": {
        "id": "yVwFuUPVzto4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Project Structure organization\n",
        "ORIGINAL_DATASET_PATH = \"original\"\n",
        "BASE_PATH = \"Dataset\"\n",
        "TRAIN_PATH = os.path.join(BASE_PATH, \"train\")\n",
        "VALIDATION_PATH = os.path.join(BASE_PATH, \"validation\")\n",
        "TEST_PATH = os.path.join(BASE_PATH, \"test\")\n",
        "\n",
        "# Train-Validation-Test split\n",
        "TRAIN_SPLIT = 0.8\n",
        "VALIDATION_SPLIT = 0.1\n",
        "\n",
        "# Parameters for training\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 64\n",
        "VERBOSE = 1\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "# callback parameters\n",
        "PATIENCE = 10"
      ],
      "metadata": {
        "id": "cYwxtWUpzrxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Setting up the project directory\n",
        "\n",
        "As the dataset is too large to load into memory, the dataset will be batched and loaded from disk. As such, there is a need to organise the project directory."
      ],
      "metadata": {
        "id": "-RIq-HSF46JT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_images(file_path):\n",
        "  '''\n",
        "  Returns the images within a folder\n",
        "  file_path: path to a folder whose subfolders contain images\n",
        "  valid image types: png, jpeg\n",
        "  '''\n",
        "  \n",
        "  VALID_IMAGE_TYPE = \"png\"\n",
        "  \n",
        "  images = []\n",
        "\n",
        "  # walk through \n",
        "  for (root, dirs, files) in os.walk(file_path, topdown = True):\n",
        "    images_sub = [os.path.join(root, file_) for file_ in files if VALID_IMAGE_TYPE in file_]\n",
        "    images.extend(images_sub)\n",
        "  \n",
        "  return images"
      ],
      "metadata": {
        "id": "s-SC6fhizwIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grab all the image file paths\n",
        "image_paths = list_images(ORIGINAL_DATASET_PATH)\n",
        "\n",
        "# randomize the order of the files\n",
        "random.seed(42)\n",
        "random.shuffle(image_paths)\n",
        "\n",
        "# conduct the split\n",
        "train_image_paths = image_paths[:int(len(image_paths) * TRAIN_SPLIT)]\n",
        "validation_image_paths = train_image_paths[:int(len(train_image_paths) * VALIDATION_SPLIT):]\n",
        "train_image_paths = train_image_paths[int(len(train_image_paths) * VALIDATION_SPLIT):]\n",
        "test_image_paths = image_paths[int(len(image_paths) * TRAIN_SPLIT):]"
      ],
      "metadata": {
        "id": "hKCz-tx_1kQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new folder to organize the data \n",
        "if not os.path.exists(BASE_PATH):\n",
        "  os.mkdir(BASE_PATH)\n",
        "\n",
        "dataset = {TRAIN_PATH: train_image_paths, VALIDATION_PATH: validation_image_paths, TEST_PATH: test_image_paths}\n",
        "for PATH, image_paths in dataset.items():\n",
        "    for image_path in image_paths:\n",
        "        # create a new folder to organize the train data\n",
        "        if not os.path.exists(PATH):\n",
        "            os.mkdir(PATH)\n",
        "        \n",
        "        # extract the label and name\n",
        "        name = image_path.split(os.path.sep)[-1]\n",
        "        label = name[-5]\n",
        "\n",
        "        # create a new folder to store the image\n",
        "        if not os.path.isdir(os.path.join(PATH, label)):\n",
        "            os.mkdir(os.path.join(PATH, label))\n",
        "        \n",
        "        # copy the image\n",
        "        shutil.copy(image_path, os.path.join(PATH, label, name))"
      ],
      "metadata": {
        "id": "HGDFJw1zzyHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"[INFO] Number of train images \\t: {len(train_image_paths)}\")\n",
        "print(f\"[INFO] Number of validation images \\t: {len(validation_image_paths)}\")\n",
        "print(f\"[INFO] Number of test images \\t: {len(test_image_paths)}\")"
      ],
      "metadata": {
        "id": "X1Mjo7LlMjxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Preprocessing\n",
        "\n",
        "Create the image datasets for the model."
      ],
      "metadata": {
        "id": "DRuJvUVe9nbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the training data augmentation object\n",
        "trainAug = ImageDataGenerator(\n",
        "\trescale=1 / 255.0,\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.05,\n",
        "\twidth_shift_range=0.1,\n",
        "\theight_shift_range=0.1,\n",
        "\tshear_range=0.05,\n",
        "\thorizontal_flip=True,\n",
        "\tvertical_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "\n",
        "# initialize the validation (and testing) data augmentation object\n",
        "valAug = ImageDataGenerator(rescale=1 / 255.0)"
      ],
      "metadata": {
        "id": "pOnigdqJ2-7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the training generator\n",
        "trainGen = trainAug.flow_from_directory(\n",
        "\tTRAIN_PATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(48, 48),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=True,\n",
        "\tbatch_size=BATCH_SIZE)\n",
        "\n",
        "# initialize the validation generator\n",
        "valGen = valAug.flow_from_directory(\n",
        "\tVALIDATION_PATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(48, 48),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=BATCH_SIZE)\n",
        "\n",
        "# initialize the testing generator\n",
        "testGen = valAug.flow_from_directory(\n",
        "\tTEST_PATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(48, 48),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "XqMuMXIV3EN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the weights to address the class inbalance."
      ],
      "metadata": {
        "id": "vfBbKJw5CY2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = [int(p.split(os.path.sep)[-2]) for p in train_image_paths]\n",
        "train_labels = to_categorical(train_labels)\n",
        "class_totals = train_labels.sum(axis=0)\n",
        "class_weight = dict()\n",
        "\n",
        "# loop over all classes and calculate the class weight\n",
        "for i in range(0, len(class_totals)):\n",
        "\tclass_weight[i] = class_totals.max() / class_totals[i]"
      ],
      "metadata": {
        "id": "cQSlZzCNxtZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Model Creation and Testing\n",
        "\n",
        "Train and Test the models."
      ],
      "metadata": {
        "id": "1fJHU-poIlvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build(width, height, depth, classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # CONV2D -> ACTIVATION -> BN -> MAXPOOLING2D -> DROPOUT\n",
        "    model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(height, width, depth), activation='relu'))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # (CONV => RELU => BN) * 2 -> MAXPOOLING2D -> DROPOUT\n",
        "    model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # (CONV => RELU => BN) * 3 -> MAXPOOLING2D -> DROPOUT\n",
        "    model.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # FC\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # DENSE -> ACTIVATION -> BN -> DROPOUT\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # DENSE -> SOFTMAX\n",
        "    model.add(Dense(classes))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "\n",
        "    # compile model\n",
        "    optimizer = Adagrad(learning_rate = LEARNING_RATE, decay = LEARNING_RATE / EPOCHS)\n",
        "    model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "7q9xaeChApqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# callbacks\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor = \"val_accuracy\", patience = PATIENCE, restore_best_weights = True)"
      ],
      "metadata": {
        "id": "upW9fXOnDeDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "model = build(48, 48, 3, 2)\n",
        "H = model.fit(trainGen, steps_per_epoch=len(train_image_paths) // BATCH_SIZE, validation_data = valGen, validation_steps=len(validation_image_paths) // BATCH_SIZE, epochs = EPOCHS, verbose = VERBOSE, batch_size = BATCH_SIZE, callbacks = [es], class_weight = class_weight)"
      ],
      "metadata": {
        "id": "Wm6D-hxOLIeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model\n",
        "testGen.reset()\n",
        "predictions = model.predict(testGen, steps=(len(test_image_paths) // BATCH_SIZE) + 1).argmax(axis=1)\n",
        "print(classification_report(testGen.classes, predictions, target_names=testGen.class_indices.keys()))"
      ],
      "metadata": {
        "id": "TpmHvkQp05ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the confusion matrix and and calculate accuracy, sensitivity, and specificity\n",
        "cm = confusion_matrix(testGen.classes, predictions)\n",
        "total = sum(sum(cm))\n",
        "acc = (cm[0, 0] + cm[1, 1]) / total\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "\n",
        "print(cm)\n",
        "print(\"acc: {:.4f}\".format(acc))\n",
        "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
        "print(\"specificity: {:.4f}\".format(specificity))"
      ],
      "metadata": {
        "id": "aDysGpNG7aHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the learning curve\n",
        "N = len(H['validation_accuracy'])\n",
        "plt.figure()\n",
        "plt.plot(np.arange(N), H['loss'], label='loss')\n",
        "plt.plot(np.arange(N), H['accuracy'], label='accuracy')\n",
        "plt.plot(np.arange(N), H['validation_loss'], label='validation loss')\n",
        "plt.plot(np.arange(N), H['validation_accuracy'], label='validation accuracy')\n",
        "plt.title(\"Learning Curve\")\n",
        "plt.xlabel(\"Epoch Number\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc='lower left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ir18Ger-sD6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qd3D-FD6ALDr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}